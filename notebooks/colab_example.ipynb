{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# River\n",
    "\n",
    "To use river in Google Colab execute the cell and restart the runtime environment.\n",
    "\n",
    "Entorno de ejecución > Reinicar entorno de ejecución\n",
    "\n",
    "The Google Colab environment already includes most of the used libraries, but river has to be installed manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install river"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "\n",
    "The src folder can be imported, or the code for each class can be copied into the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class OnlineBagging:\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_classifier_class,\n",
    "        n_classifiers: int = 25,\n",
    "        lambda_diversity: float = 1,\n",
    "        p_classifiers: dict = {},\n",
    "        class_list: list = [0, 1],\n",
    "    ):\n",
    "        \"\"\"Ensemble with online bagging, it uses lambda_diversity to control its diveristy\n",
    "\n",
    "        base_classifier_class: classifier class that implements the BaseClassifier interface\n",
    "        n_classifiers: number of classifiers\n",
    "        lambda_diversity: paremeter for forcing diversity when learning (higher means lower diversity)\n",
    "        p_classifiers: dictionary with parameters for the classifiers initialization\n",
    "        list_classes: list of classes to predict\n",
    "        \"\"\"\n",
    "        self.base_classifier_class = base_classifier_class\n",
    "        self.lambda_diversity = lambda_diversity\n",
    "        self.n_classifiers = n_classifiers\n",
    "        self.p_classifiers = p_classifiers\n",
    "        self.classifier_list = [self.base_classifier_class(**self.p_classifiers) for _ in range(self.n_classifiers)]\n",
    "        self.class_list = class_list\n",
    "\n",
    "    def predict_one(self, x: dict):\n",
    "        # Get all base classifiers predictions at once\n",
    "        pred_arr = np.array([clf.predict_one(x) for clf in self.classifier_list])\n",
    "        # Remove None predictions as they will crash numpy\n",
    "        pred_arr = pred_arr[pred_arr != np.array(None)]\n",
    "        # If all are None, return the first class\n",
    "        if pred_arr.size == 0:\n",
    "            return self.class_list[0]\n",
    "        # Return most common value\n",
    "        values, counts = np.unique(pred_arr, return_counts=True)\n",
    "        return values[counts.argmax()]\n",
    "\n",
    "    def predict_proba_one(self, x: dict):\n",
    "        y_pred_proba = {}\n",
    "        for clf in self.classifier_list:\n",
    "            pred = clf.predict_proba_one(x)\n",
    "            for key, value in pred.items():\n",
    "                y_pred_proba[key] = y_pred_proba.get(key, 0) + value / self.n_classifiers\n",
    "        return y_pred_proba\n",
    "\n",
    "    def learn_one(self, x: dict, y):\n",
    "        # For each base classifier draw k from the poisson distribution and learn k times\n",
    "        for i in range(self.n_classifiers):\n",
    "            k = np.random.poisson(self.lambda_diversity)\n",
    "            for _ in range(k):\n",
    "                self.classifier_list[i].learn_one(x, y)\n",
    "\n",
    "    def reset(self):\n",
    "        self.classifier_list = [self.base_classifier_class(**self.p_classifiers) for _ in range(self.n_classifiers)]\n",
    "\n",
    "\n",
    "class ConvexMetrics:\n",
    "    def __init__(self, gamma: float = 0.9, mu: float = 1, lambda_error: float = 0.05, store_metrics: bool = False):\n",
    "        # For the first use, first combine and then update\n",
    "        # By default 1 is low div (fast), 2 is high div (slow)\n",
    "        # Convex Combination parameters\n",
    "        self.gamma = gamma  # forgetting factor\n",
    "        self.mu = mu  # step size\n",
    "        self.lambda_error = lambda_error\n",
    "        self.store_metrics = store_metrics\n",
    "\n",
    "        # Initial values\n",
    "        self.B = 0.5\n",
    "        self.a = 0.0\n",
    "        self.p = 0.5\n",
    "\n",
    "        if self.store_metrics:\n",
    "            # Store metrics\n",
    "            self.B_list = []\n",
    "            self.a_list = []\n",
    "            self.p_list = []\n",
    "\n",
    "    def combine(self, y1: float, y2: float):\n",
    "        y = self.B * y1 + (1 - self.B) * y2\n",
    "        return y\n",
    "\n",
    "    def update(self, e: float, e1: float, e2: float):\n",
    "        self.p = self.gamma * self.p + (1 - self.gamma) * np.power((e2 - e1), 2)\n",
    "        # Get new a from updated p and e\n",
    "        # Multiplying by 0.99 (or gamma) was added later to avoid a scaling to infinity\n",
    "        self.a = 0.99 * self.a + (self.mu / self.p) * e * (e2 - e1) * self.lambda_error\n",
    "        # Use new a to get new B which will be used for next prediction\n",
    "        self.B = 1 / (1 + np.exp(-self.a))\n",
    "\n",
    "        if self.store_metrics:\n",
    "            # Store metrics\n",
    "            self.B_list.append(self.B)\n",
    "            self.a_list.append(self.a)\n",
    "            self.p_list.append(self.p)\n",
    "\n",
    "\n",
    "class ConvexCombination:\n",
    "    def __init__(\n",
    "        self,\n",
    "        fast_learner,\n",
    "        slow_learner,\n",
    "        p_convex: dict = {},\n",
    "        use_binary_error: bool = False,\n",
    "        class_list: list = [0, 1],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Wrapper for two river learners (fast and slow) to use convex combination.\n",
    "        Note there is no drift detection.\n",
    "\n",
    "        fast_learner: fast learner\n",
    "        slow_learner: slow learner\n",
    "        p_convex = parameters for convex combination\n",
    "        \"\"\"\n",
    "        # By default 1 is low div (fast), 2 is high div (slow)\n",
    "        self.fast_learner = fast_learner\n",
    "        self.slow_learner = slow_learner\n",
    "        self.p_convex = p_convex\n",
    "        self.use_binary_error = use_binary_error # Quizas actualizar cada 10 samples?\n",
    "        self.class_list = class_list\n",
    "\n",
    "        self.convex = ConvexMetrics(**self.p_convex)\n",
    "\n",
    "    def predict_one(self, x: dict, include_individual: bool = False):\n",
    "        if include_individual:\n",
    "            y_pred_proba, y_fast_proba, y_slow_proba = self.predict_proba_one(x, include_individual=True)\n",
    "            return (\n",
    "                max(y_pred_proba, key=lambda k: y_pred_proba[k]),\n",
    "                max(y_fast_proba, key=lambda k: y_fast_proba[k]),\n",
    "                max(y_slow_proba, key=lambda k: y_slow_proba[k]),\n",
    "            )\n",
    "        else:\n",
    "            y_pred_proba = self.predict_proba_one(x)\n",
    "            return max(y_pred_proba, key=lambda k: y_pred_proba[k])\n",
    "\n",
    "    def predict_proba_one(self, x: dict, include_individual: bool = False) -> dict:\n",
    "        # Obtain the predictions\n",
    "        y_fast_proba = self.fast_learner.predict_proba_one(x)\n",
    "        y_slow_proba = self.slow_learner.predict_proba_one(x)\n",
    "        # Obtain the weighted probability of every label\n",
    "        y_pred_proba = {}\n",
    "        for label in self.class_list:\n",
    "            y_pred_proba[label] = self.convex.combine(y_fast_proba.get(label, 0), y_slow_proba.get(label, 0))\n",
    "\n",
    "        if include_individual:\n",
    "            y_fast_parsed = {}\n",
    "            y_slow_parsed = {}\n",
    "            for label in self.class_list:\n",
    "                y_fast_parsed[label] = y_fast_proba.get(label, 0)\n",
    "                y_slow_parsed[label] = y_slow_proba.get(label, 0)\n",
    "            return y_pred_proba, y_fast_parsed, y_slow_parsed\n",
    "\n",
    "        return y_pred_proba\n",
    "\n",
    "    def learn_one(self, x: dict, y_true):\n",
    "        # Update convex combination\n",
    "        if self.use_binary_error:\n",
    "            y_pred, y_fast, y_slow = self.predict_proba_one(x, include_individual=True)\n",
    "            e = 0 if y_pred == y_true else 1\n",
    "            e1 = 0 if y_fast == y_true else 1\n",
    "            e2 = 0 if y_slow == y_true else 1\n",
    "        else:\n",
    "            y_pred, y_fast, y_slow = self.predict_proba_one(x, include_individual=True)\n",
    "            e = 1 - y_pred.get(y_true, 0)\n",
    "            e1 = 1 - y_fast.get(y_true, 0)\n",
    "            e2 = 1 - y_slow.get(y_true, 0)\n",
    "        self.convex.update(e, e1, e2)\n",
    "\n",
    "        # Update ensembles\n",
    "        self.fast_learner.learn_one(x, y_true)\n",
    "        self.slow_learner.learn_one(x, y_true)\n",
    "\n",
    "\n",
    "class DriftDetectorWrapper:\n",
    "    def __init__(self, classifier, drift_detector, train_in_background: bool = True):\n",
    "        \"\"\"Wrapper for an OnlineBagging classifier with a drift detector (DDM or EDDM).\n",
    "\n",
    "        classifier: classifier instance that implements the BaseClassifier interface and has a reset method. Usually OnlineBagging.\n",
    "        drift_detector: drift detector instance that implements the DriftDetector interface.\n",
    "        \"\"\"\n",
    "        self.classifier = classifier\n",
    "        self.drift_detector = drift_detector\n",
    "        self.train_in_background = train_in_background\n",
    "\n",
    "        self.in_warning = False\n",
    "        self.X_warning = []\n",
    "        self.y_warning = []\n",
    "\n",
    "    def predict_one(self, x: dict):\n",
    "        return self.classifier.predict_one(x)\n",
    "\n",
    "    def predict_proba_one(self, x: dict):\n",
    "        return self.classifier.predict_proba_one(x)\n",
    "\n",
    "    def learn_one(self, x: dict, y_true, y_pred=None):\n",
    "        if y_pred is None:\n",
    "            y_pred = self.predict_one(x)\n",
    "\n",
    "        if y_true == y_pred:\n",
    "            prediction = 0\n",
    "        else:\n",
    "            prediction = 1\n",
    "        self.drift_detector.update(prediction)\n",
    "\n",
    "        # Check if drift was detected\n",
    "        detected = \"\"\n",
    "        if self.drift_detector.drift_detected:\n",
    "            self.reset()\n",
    "            detected = \"drift\"\n",
    "\n",
    "        if self.train_in_background:\n",
    "            # If entering warning zone, trigger warning flag\n",
    "            if self.drift_detector.warning_detected and not self.in_warning:\n",
    "                self.in_warning = True\n",
    "                detected = \"warning\"\n",
    "\n",
    "            if self.in_warning:\n",
    "                # Check if we have exited warning zone\n",
    "                if not self.drift_detector.warning_detected:\n",
    "                    self.X_warning = []\n",
    "                    self.y_warning = []\n",
    "                    detected = \"exited warning\"\n",
    "                else:\n",
    "                    self.X_warning.append(x)\n",
    "                    self.y_warning.append(y_true)\n",
    "\n",
    "        # Learn instance and return true if drift was detected\n",
    "        self.classifier.learn_one(x, y_true)\n",
    "        return detected\n",
    "\n",
    "    def reset(self):\n",
    "        self.in_warning = False\n",
    "        self.classifier.reset()\n",
    "        for i in range(len(self.X_warning)):\n",
    "            self.classifier.learn_one(self.X_warning[i], self.y_warning[i])\n",
    "        self.X_warning = []\n",
    "        self.y_warning = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sine high speed high severity\n",
    "from river.datasets import synth\n",
    "from itertools import chain\n",
    "\n",
    "class_list = [0, 1]\n",
    "n_samples = 10000\n",
    "\n",
    "stream1 = synth.Sine(classification_function=2, balance_classes=True, has_noise=True)\n",
    "stream2 = synth.Sine(classification_function=3, balance_classes=True, has_noise=True)\n",
    "stream3 = synth.Sine(classification_function=2, balance_classes=True, has_noise=True)\n",
    "\n",
    "dataset = chain(stream1.take(3000), stream2.take(3000), stream3.take(4000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a function as a constructor for the logistic regression model\n",
    "from river import preprocessing, optim, linear_model\n",
    "\n",
    "\n",
    "def get_logis_reg():\n",
    "    return preprocessing.StandardScaler() | linear_model.LogisticRegression(\n",
    "        optimizer=optim.SGD(0.1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import tree, drift\n",
    "\n",
    "p_ht = {\"delta\": 1e-07, \"max_depth\": 25}\n",
    "p_drift_detector = {\"alpha\": 0.90, \"beta\": 0.85}\n",
    "p_convex = {\"gamma\": 0.9, \"mu\": 1, \"lambda_error\": 0.95, \"store_metrics\": True}\n",
    "\n",
    "p_slow_ensemble = {\n",
    "    \"base_classifier_class\": tree.HoeffdingTreeClassifier,\n",
    "    \"n_classifiers\": 10,\n",
    "    \"lambda_diversity\": 1,\n",
    "    \"p_classifiers\": p_ht,\n",
    "    \"class_list\": class_list,\n",
    "}\n",
    "p_fast_ensemble = {\n",
    "    \"base_classifier_class\": get_logis_reg,\n",
    "    \"n_classifiers\": 10,\n",
    "    \"lambda_diversity\": 1,\n",
    "    \"p_classifiers\": {},\n",
    "    \"class_list\": class_list,\n",
    "}\n",
    "slow_learner = DriftDetectorWrapper(\n",
    "    OnlineBagging(**p_slow_ensemble),\n",
    "    drift.binary.EDDM(**p_drift_detector),\n",
    "    train_in_background=False,\n",
    ")\n",
    "fast_learner = OnlineBagging(**p_fast_ensemble)\n",
    "convex_model = ConvexCombination(\n",
    "    fast_learner, slow_learner, p_convex=p_convex, class_list=class_list\n",
    ")\n",
    "\n",
    "n_models = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists for storing predictions convex\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    y_pred_list.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic loop for convex storing predictions\n",
    "for idx, (x, y) in enumerate(dataset):\n",
    "    # Predict and update the model\n",
    "    y_convex, y_fast, y_slow = convex_model.predict_one(x, include_individual=True)\n",
    "    convex_model.learn_one(x, y)\n",
    "\n",
    "    y_true_list.append(y)\n",
    "    y_pred_list[0].append(y_convex)\n",
    "    y_pred_list[1].append(y_fast)\n",
    "    y_pred_list[2].append(y_slow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "from river import metrics, utils\n",
    "\n",
    "\n",
    "metrics_list = []\n",
    "metrics_cum_list = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    model_metrics = [utils.Rolling(metrics.Accuracy(), 250), utils.Rolling(metrics.Accuracy(), 1000)]\n",
    "    n_metrics = len(model_metrics)\n",
    "\n",
    "    metrics_list.append(model_metrics)\n",
    "    metrics_cum_list.append([[] for _ in range(n_metrics)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to metrics\n",
    "for i in range(n_models):\n",
    "    for idx in range(len(y_true_list)):\n",
    "        y = y_true_list[idx]\n",
    "        y_pred = y_pred_list[i][idx]\n",
    "        # Update the metrics\n",
    "        for j in range(n_metrics):\n",
    "            try:\n",
    "                metrics_list[i][j].update(y, y_pred)\n",
    "            except:\n",
    "                metrics_list[i][j].update(y, class_list[0])\n",
    "                print(\"ERROR\")\n",
    "            metrics_cum_list[i][j].append(metrics_list[i][j].get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metric_n = 1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(1, n_samples + 1), metrics_cum_list[1][metric_n], \"-\", color=\"tab:orange\", label=f\"Fast\")\n",
    "ax.plot(range(1, n_samples + 1), metrics_cum_list[2][metric_n], \"-\", color=\"tab:blue\", label=f\"Slow\")\n",
    "ax.plot(range(1, n_samples + 1), metrics_cum_list[0][metric_n], \":\", color=\"k\", label=f\"Convex\")\n",
    "ax.set_xlim(0, n_samples)\n",
    "ax.set_ylim(0.5, 1)\n",
    "ax.set_xlabel(\"Time step\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "#ax.set_title(\"Graph title\")\n",
    "ax.legend(loc=\"lower left\")\n",
    "ax.grid()\n",
    "print(f\"Executed {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aelec11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
